# Read Me First

## Objective

* This microservice is designed to store chat histories generated by a RAG (Retrieval-Augmented Generation) based chatbot system.  
* Each conversation between a user and the AI assistant is securely stored along with any relevant retrieved context to enable seamless session management and retrieval.
* The objective of this microservice is to efficiently manage user sessions, store messages, and provide an API interface for interacting with the chat system, ensuring that both user queries and AI responses are properly persisted for future reference.
# Getting Started

### Prerequisites
To run this project locally, you need the following:

* Java 17 (Corretto)
* Maven
* Docker & Docker Compose
* Ollama (for LLM integration)

### Reference Documentation
For further reference, please consider the following sections:

* [Official Apache Maven documentation](https://maven.apache.org/guides/index.html)
* [Spring Boot Maven Plugin Reference Guide](https://docs.spring.io/spring-boot/3.5.8/maven-plugin)
* [Spring Web](https://docs.spring.io/spring-boot/3.5.8/reference/web/servlet.html)
* [Ollama](https://docs.spring.io/spring-ai/reference/api/chat/ollama-chat.html)
* [PGvector Vector Database](https://docs.spring.io/spring-ai/reference/api/vectordbs/pgvector.html)

### Guides
The following guides illustrate how to use some features concretely:

* [Building a RESTful Web Service](https://spring.io/guides/gs/rest-service/)
* [Serving Web Content with Spring MVC](https://spring.io/guides/gs/serving-web-content/)
* [Building REST services with Spring](https://spring.io/guides/tutorials/rest/)

# Project Setup

### Ollama Setup
Install and start Ollama locally:

```bash
brew install ollama
brew services start ollama
ollama pull mistral # pull mistral model
```

### Docker Compose Setup

You can run the application with Docker Compose. Here’s an example docker-compose.yml:
```yaml
version: '3.9'

services:
  rag-postgres:
    image: postgres:17
    container_name: rag-postgres
    environment:
      POSTGRES_DB: chatdb
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data

  rag-app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: rag-app
    depends_on:
      - rag-postgres
    environment:
      SPRING_DATASOURCE_URL: jdbc:postgresql://rag-postgres:5432/chatdb
      SPRING_DATASOURCE_USERNAME: admin
      SPRING_DATASOURCE_PASSWORD: admin
      LLM_BASE_URL: http://host.docker.internal:11434
    ports:
      - "8080:8080"

volumes:
  pgdata:

```

### Running the Application
1. Build the Spring Boot Application
```bash
mvn clean install
```
2. Build Docker Images without cache
```bash
docker-compose build --no-cache
```
3. Start the application:
```bash
docker-compose up
```
The application will run on port 8080 by default. 

### Postgres DB

Postgres DB initialization and table setup will be taken care during docker initialization.

Database Tables
```text
1. users – Stores information about the users of the application.  
2. sessions – Contains session data associated with each user.  
3. messages – Records the conversation between the user and the assistant.  ```
```

### API Details

```text
1. /user – Used to create a new user.  
2. /session – Manages user sessions, including creating a session, renaming it, updating favorites, and deleting a session.  
3. /chat – Handles retrieving conversation history for a session and allows the user to chat with the assistant.  
```

### API Documentation
```text
Swagger UI is available at: 'http://localhost:8080/swagger-ui.html`  
Open this URL in your browser to explore and test the APIs interactively.
```

### Configuration

The application uses the following environment variables:
```text
SPRING_DATASOURCE_URL – JDBC URL for PostgreSQL (default: `jdbc:postgresql://postgres:5432/<DB Name>`)
LLM_BASE_URL – Base URL for the LLaMA / Ollama server (default: `http://host.docker.internal:11434`)

```
### Sample API Requests

Create a user:
```bash
curl -X POST http://localhost:8080/user \
-H "Content-Type: application/json" \
-d '{"name":"John Doe"}'
```
Create a session:
```bash
curl -X POST http://localhost:8080/session \
-H "Content-Type: application/json" \
-d '{"userId":"<USER_UUID>","title":"My Session"}'
```
Chat with assistant
```bash
curl -X POST http://localhost:8080/chat \
-H "Content-Type: application/json" \
-d '{"sessionId":"<SESSION_UUID>","message":"Hello"}'

```
